{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial neural networks can tackle highly complex ML tasks, such as image classification, speech recognition, predicting stocks, playing games... They are the core of Deep Learning.\n",
    "\n",
    "Why ``playing`` with NN is fun? Because they can have different **architectures**. It is up to you and your creativity to find the best architectures to solve your problem.\n",
    "\n",
    "The idea behind artificial neuronal network is a biological neuronal system. Neurons are typically organized in **layers**.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/rukcytf4xm8frz1/bio_neuron_layers.png?dl=0\" width=\"800\">\n",
    "\n",
    "A neuron is a cell is composed of cell body, many branching extensions called dendrites, and one long extension called axon.\n",
    "The neuron  receives short eletrical signals from other neurons that are attached to its dendrites. But only when the signal increases a certain treshold, it also fires a signal that goes through the axos and reaches the next layer of neurons.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/9jeij0scgtgij18/bio_neuron.png?dl=0\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biological neurons are not activated by any signal they receive, but the suppress the input until it has grown large enough (threshold).\n",
    "\n",
    "The artificial neurons work exactly in the same way. \n",
    "They have multiple inputs. They add them up. Accordingly to a certain treshold, if the resulting input is large enough, then the neuron is activated and fires a signal. Otherwise, the signal is suppressed.\n",
    "\n",
    "The function that takes the input signal and generates an output signal given a threshold is called an **activation function**. And the result of the activation function is also the output of the neuron.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/i0g07tonai21phb/artifical_neuron.png?dl=0\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Perceptron (invented in 1957)\n",
    "\n",
    "The most basic and oldest type of ANN is the perceptron. It was invented in 1957 by Frank Rosenblatt. It is made up of only one neuron that accepts the input and applies an activation function to it in order to generate a binary output.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/x1t7go0h7yncp2q/perceptron.png?dl=0\" width=\"800\">\n",
    "\n",
    "Each input connection is associated with a weight. The perceptron computes a weighted sum of its inputs \n",
    "\n",
    "$\\Large z = w_{0} + w_{1} x_{1} + w_{2} x_{2} + ⋯ + w_{n} x_{n} = x^{T} w$ \n",
    "\n",
    "then applies a step function to that sum and outputs the result\n",
    "\n",
    "$\\Large output = h(z)$\n",
    "\n",
    "The activation function can be a step function.\n",
    "\n",
    "$\\Large h(z) = \\begin{cases}\n",
    "      0~~~if~~~z<0\\\\\n",
    "      1~~~~~if~~~z\\geq0\n",
    "    \\end{cases}$\n",
    "\n",
    "\n",
    "Training the Perceptron means finding the best set of weights that can perform the task. Note that there is always a bias term!\n",
    "\n",
    "The decision boundary of each output neuron is linear, so Perceptrons are incapable of learning complex patterns (just like Logistic Regression classifiers). This is like drawing an hyperplane in the space of input features and then use it as decision bounday. So, Perceptrons can be used for linear classification problems, they cannot do much more than that. However, if the training instances are linearly separable, Perceptrons would always converge to a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=&seed=0.58206&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\">Example of Perceptron</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron\n",
    "\n",
    "The decision boundary of the Perceptron is always linear. So Perceptrons are incapable of learning complex patterns. This limitation can be eliminated by stacking multiple Perceptrons. The resulting ANN is a Multi-layer Perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is equivalent to add an **hidden layer** of two neurons between the **input layer** and the **output layer**.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/4g0xvalf58x9ju7/ANN_1.png?dl=0\" width=\"800\">\n",
    "\n",
    "<a href=\"https://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=2&seed=0.69416&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\">Example of Multi-Layer Perceptron</a>\n",
    "\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/s2ovjqzrvpevie6/ANN_2.png?dl=0\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectivity\n",
    "\n",
    "A layer where all the nodes are connected to all the nodes of the previous and following layer is called **dense layer** or **fully connected** layer. \n",
    "\n",
    "Why connect each node with each other node in the next layer?\n",
    "\n",
    "Why not establish a more creative network? Full connectivity is much easier to code. If a connection is not needed the weight will be set to zero by the learning process. The connection weights are the trainable parameters of the model and get adjusted!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "\n",
    "Why do we need activation functions in the first place? \n",
    "\n",
    "If you chain several linear transformations, all you get is a linear transformation. For example, \n",
    "\n",
    "$f(x) = 2 x + 3$ \n",
    "\n",
    "and \n",
    "\n",
    "$g(x) = 5 x - 1$ \n",
    "\n",
    "then chaining these two linear functions gives you another linear function: \n",
    "\n",
    "$f(g(x)) = 2(5 x - 1) + 3 = 10 x + 1$\n",
    "\n",
    "So if you don’t have some non-linearity between layers, then even a deep stack of layers is equivalent to a single layer: you cannot solve very complex problems with that.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/i0vohs2bzttigb8/activation_functions.png?dl=0\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Input layer\n",
    "\n",
    "The input layer contains as many neurons as the number of input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The output layer\n",
    "\n",
    "**Regression**. \n",
    "\n",
    "If you want to predict a single value (e.g., the price of a house given many of its features), then you just need a single output neuron: its output is the predicted value. For multivariate regression (i.e., to predict multiple values at once), you need one output neuron per output dimension. \n",
    "\n",
    "In general, for regression you do not want to use any activation function for the output neurons, so they are free to output any range of values. However, if you want to guarantee that the output will always be positive, then you can use the ReLU activation function. If you want to guarantee that the predictions will fall within a given range of values, then you can use the logistic function or the tanh, and scale the labels to the appropriate range.\n",
    "\n",
    "**Classification**\n",
    "\n",
    "For a binary classification problem, you just need a single output neuron using the logistic activation function: the output will be a number between 0 and 1, which you can interpret as the estimated probability of the positive class.\n",
    "\n",
    "For multiclass classification you need to have one output neuron per class, and you should use the softmax activation function for the whole output layer.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/zcxro1w45y03k93/ANN_multi_class.png?dl=0\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many hidden layers? How many neurons?\n",
    "\n",
    "- Each neuron in the first hidden layer adds a decision boundary hyperplane.\n",
    "\n",
    "- Adding a second hidden layer will perform a linear combination of the decision boundary hyperplanes given by the first hidden layers\n",
    "\n",
    "<a href=\"https://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=2&seed=0.69416&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\">Example of Multi-Layer Perceptron</a>\n",
    "\n",
    "- The lower hidden layers model low-level structures (e.g., line segments of various shapes and orientations), the intermediate hidden layers combine these low-level structures to model intermediate-level structures (e.g., squares, circles), and the highest hidden layers and the output layer combine these intermediate structures to model high-level structures (e.g., faces).\n",
    "\n",
    "- My advice. Typically 1-5 hidden layers will solve most of the problems. Increase the number of hydden layers only if you are working with images, videos, and audios. Each layer should contain 1-500 neurons. Something to keep in mind with choosing a smaller number of layers/neurons is that if the this number is too small, your network will not be able to learn the underlying patterns in your data and thus be useless. Instead, if the number of layers/neurons is too large, you simply overfit. So, a good approach is to start with a large number of layers/neurons and progressively reduce this number or regularize in order to reduce overfitting (i.e., the **stretch pants approach**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stretch pants approach\n",
    "\n",
    "Finding the right number of neurons and layers is a dark art which requires a lot of experience. However, a simple approach to pick the right number of neurons and layers is the **stretch pants approach**. You pick a model with more layers and neurons than you actually need, then use early stopping to prevent it from overfitting. Or you gradually reduce the number of layers and neurons untill the model stops overfitting. \n",
    "\n",
    "In other words, instead of wasting time looking for pants that perfectly match your size, just use large stretch pants that will shrink down to the right size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network weights - Backpropagation \n",
    "\n",
    "Suppose that we want to train an ANN to reproduce some stellar spectra given the stellar labels (temperature, surface gravity, metallicity). The trainig sample is composed by spectra of stars whose labels are known.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/vxo84ex382z9hwz/project_ANN.png?dl=0\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First thing first, you have to define a loss function. A very common one is the square difference between the predicted value and the true value. The loss function is calculated for every i$^{th}$ element in your training sample.\n",
    "\n",
    "$\\Large L=\\frac{1}{2}[y^{(i)}-\\hat{y}^{(i)}]^2$\n",
    "\n",
    "- The ANN handles one mini-batch at a time (for example containing 32 instances each), and it goes through the full training set multiple times. Each pass is called an **epoch**.\n",
    "\n",
    "- Each mini-batch is passed to the network’s input layer, which just sends it to the first hidden layer. The algorithm then computes the output of all the neurons in this layer (for every instance in the mini-batch). The result is passed on to the next layer, its output is computed and passed to the next layer, and so on until we get the output of the last layer, the output layer. This is the **forward pass**: it is exactly like making predictions, except all intermediate results are preserved since they are needed for the backward pass.\n",
    "\n",
    "- Next, the algorithm measures the network’s output error. It takes the average of L calculated for every instance of the mini-batch. That will return a single number for your entire mini-batch.\n",
    "\n",
    "$\\Large J(w)=\\frac{1}{2n}\\sum_{i=1}^{n}[y^{(i)}-\\hat{y}^{(i)}]^2$\n",
    "\n",
    "- Obviously this cost function J is function of the weights. So you can measure how much of these error contributions came from each connection in each layer, from the output to the input. This is done with the partial derivative of the cost function relatively to each weight and using the **chain rule**. This reverse pass efficiently measures the error gradient across all the connection weights in the network by propagating the error gradient backward through the network (hence the name of the algorithm).\n",
    "\n",
    "$\\Large \\frac{\\partial J(w)}{\\partial w_{j}}$\n",
    "\n",
    "- Finally, the algorithm performs a Gradient Descent step to tweak all the connection weights in the network, using the error gradients it just computed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Chain rule\n",
    "\n",
    "Imagine you have a plain ANN.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/b9nl84chqh5ddq5/plain_ANN.jpg?dl=0\" width=\"1000\">\n",
    "\n",
    "The chain rule tells you the following.\n",
    "\n",
    "$\\Large \\frac{\\partial J(w)}{\\partial w^{(1)}} = \\frac{\\partial J}{\\partial a^{(3)}} \\frac{\\partial a^{(3)}}{\\partial z^{(3)}} \\frac{\\partial z^{(3)}}{\\partial a^{(2)}} \\frac{\\partial a^{(2)}}{\\partial z^{(2)}} \\frac{\\partial z^{(2)}}{\\partial a^{(1)}} \\frac{\\partial a^{(1)}}{\\partial z^{(1)}} \\frac{\\partial z^{(1)}}{\\partial w^{(1)}} $\n",
    "\n",
    "Once you have that, you can correct the weight\n",
    "\n",
    "$ \\Large w^{(1)} := w^{(1)} - \\eta \\frac{\\partial J(w)}{\\partial w^{(1)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanishing gradient\n",
    "\n",
    "What can slow down the gradient descend?\n",
    "\n",
    "Assume that your activation functions are Sigmoid functions. \n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/yys9bu4eygqrigd/sigmoid.png?dl=0\" width=\"600\">\n",
    "\n",
    "The Sigmoid saturates at the extremities. So, whem the input is too high or too low, the derivative will be very close to zero.\n",
    "\n",
    "If, for instance,\n",
    "\n",
    "$\\Large \\frac{\\partial a^{(2)}}{\\partial z^{(2)}} \\sim 0$\n",
    "\n",
    "then also\n",
    "\n",
    "$\\Large \\frac{\\partial J(w)}{\\partial w^{(1)}} \\sim 0$\n",
    "\n",
    "When this happens, the gradient will get smaller and smaller as you go backward in propagating the gradient. This is the so-called **vanishing gradient**.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/qk1gmrwecywd6n4/vanishing.gif?dl=0\" width=\"300\">\n",
    "\n",
    "\n",
    "Similarly, if the various gradients are too large, I have the problem of the **exploding gradients**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The choice of the activation function\n",
    "\n",
    "Choosing the right activation function is crucial to avoid the vanishing/exploding gradient.\n",
    "\n",
    "The logistic activation function suffers of vanishing gradient. When backpropagation kicks in, it has virtually no gradient to propagate back through the network. Also, this gradient keeps getting diluted as backpropagation progresses down through the top layers, so there is really nothing left for the lower layers.\n",
    "\n",
    "Now let's consider a **ReLU activation function**. It avoids the vanishing gradient problem, but it suffers from a problem know as the **dying ReLUs**: during training, some neurons effectively die, meaning they stop outputting anything other than 0. \n",
    "\n",
    "When this happens, the weights just keeps outputting 0s, and gradient descent does not change them anymore since the gradient of the ReLU function is 0 when its input is negative.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/7738rv1y20qhr1m/relu.png?dl=0\" width=\"500\">\n",
    "\n",
    "When we face these problems it is better to choose a non-saturating activation function. For instance, a **Leaky ReLU** could be a good option in this case!\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/esw1gwcw5ovuobt/LRelu.jpg?dl=0\" width=\"700\">\n",
    "\n",
    "\n",
    "In general, the performance from using different activation functions improves in this order (from lowest→highest performing): logistic → tanh → ReLU → Leaky ReLU → ELU → SELU.\n",
    "\n",
    "[This](https://arxiv.org/pdf/1811.03378.pdf) is an excellent paper that dives deeper into the comparison of various activation functions for neural networks.\n",
    "\n",
    "As always, don't be afraid to experiment with a few different activation functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanishing gradient and the weight initialization\n",
    "\n",
    "The right weight initialization method can avoid problems with the vanishing gradient and speed up time-to-convergence considerably.\n",
    "\n",
    "The idea behing all that is the following. We need the signal to flow properly in both directions: in the forward direction when making predictions, and in the reverse direction when backpropagating gradients. We don’t want the signal to die out, nor do we want it to explode and saturate. For the signal to flow properly, we need the variance of the outputs of each layer to be equal to the variance of its inputs.\n",
    "\n",
    "Here’s an analogy: if you set a microphone amplifier’s knob too close to zero, people won’t hear your voice, but if you set it too close to the max, your voice will be saturated and people won’t understand what you are saying. Now imagine a chain of such amplifiers: they all need to be set properly in order for your voice to come out loud and clear at the end of the chain. Your voice has to come out of each amplifier at the same amplitude as it came in.\n",
    "\n",
    "There are different methods to initialise the weights. Each method works properly with a specific class of activation functions.\n",
    "\n",
    "- When using ReLU or leaky RELU, use [He initialization](https://arxiv.org/pdf/1502.01852.pdf)\n",
    "- When using SELU or ELU, use [LeCun initialization](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n",
    "- When using softmax, logistic, or tanh, use [Glorot initialization](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)\n",
    "\n",
    "Keras uses Gorot as default.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size\n",
    "\n",
    "The **batch size** defines the number of samples that will be propagated through the network.\n",
    "\n",
    "For instance, let's say you have 1050 training samples and you want to set up a batch_size equal to 100. The algorithm takes the first 100 samples (from 1st to 100th) from the training dataset and trains the network. Next, it takes the second 100 samples (from 101st to 200th) and trains the network again. We can keep doing this procedure until we have propagated all samples through of the network. \n",
    "\n",
    "Advantages of using a batch size < number of all samples.\n",
    "\n",
    "- It requires less memory. Since you train the network using fewer samples, the overall training procedure requires less memory. That's especially important if you are not able to fit the whole dataset in your machine's memory.\n",
    "\n",
    "- Typically networks train faster with mini-batches. That's because we update the weights after each propagation. \n",
    "\n",
    "- The smaller the batch the less accurate the estimate of the gradient will be. However in some cases these noisy gradients can actually help escape local minima. When it is too low, your network weights can just jump around if your data is noisy and it might be unable to learn or it converges very slowly, thus negatively impacting total computation time.\n",
    "\n",
    "Disavantages of using a batch size < number of all samples.\n",
    "\n",
    "- The smaller the batch the less accurate the estimate of the gradient will be. In the figure below, you can see that the direction of the mini-batch gradient (green color) fluctuates much more in comparison to the direction of the full batch gradient (blue color).\n",
    "\n",
    "So, by batching you have influence over training speed vs. gradient estimation accuracy. By choosing the batch size you define how many training samples are combined to estimate the gradient before updating the parameter(s).\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/xs2up2l8kbazkvl/min-batch.png?dl=0\" width=\"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "Dropout is one of the most popular regularization techniques for deep and dense neural networks.\n",
    "\n",
    "It is a fairly simple algorithm: at every training step, every neuron (including the input neurons, but always excluding the output neurons) has a probability p of being temporarily “dropped out,” meaning it will be entirely ignored during this training step, but it may be active during the next step. The hyperparameter p is called the dropout rate, and it is typically set to 50%. After training, neurons don’t get dropped anymore. \n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/raxvz3jara2qukw/dropout.png?dl=0\" width=\"700\">\n",
    "\n",
    "Here is an analogy. A company asks to its employees to toss a coin every morning to decide whether or not to go to work. By doing this, the company would be forced to adapt its organization; it could not rely on any single person to fill in the coffee machine or perform any other critical tasks, so this expertise would have to be spread across several people. Employees would have to learn to cooperate with many of their coworkers, not just a handful of them. The company would become much more resilient. If one person gets covid, it wouldn’t make much of a difference. It’s unclear whether this idea would actually work for companies, but it certainly does for neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network terminology\n",
    "\n",
    "- **batch size** = the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need.\n",
    "\n",
    "- number of **iterations** = number of passes, each pass using (batch size) number of examples.\n",
    "\n",
    "- one **epoch** = one forward pass and one backward pass of all the training examples\n",
    "\n",
    "- **input layer** and **output layer**. The first and last layer of neurons.\n",
    "\n",
    "- **hidden layer**. Is any layer in between the input and the output layers.\n",
    "\n",
    "- **activation function**\n",
    "\n",
    "- **weight initialization**\n",
    "\n",
    "- **optimizer**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "\n",
    "Training a very large deep neural network can be painfully slow. A huge speed boost comes from using a fast optimizer. Gradient Descent and Stochastic Gradient Descent aren't the only optimizers in town! There's a few different ones to choose from.\n",
    "\n",
    "- Momentum\n",
    "- Nesterov Accelerated Gradient\n",
    "- AdaGrad\n",
    "- RMSProp\n",
    "- AdaDelta\n",
    "- Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum Optimization\n",
    "\n",
    "Imagine a bowling ball rolling down a gentle slope on a smooth surface: it will start out slowly, but it will quickly pick up momentum until it eventually reaches terminal velocity (if there is some friction or air resistance). \n",
    "\n",
    "Recall that Gradient Descent simply updates the weights $\\theta$ by directly subtracting the gradient of the cost function $J(\\mathbf{\\theta})$ with regards to the weights ($\\nabla_\\theta J(\\mathbf{\\theta})$) multiplied by the learning rate $\\eta$.\n",
    "\n",
    "$\\Large \\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J(\\mathbf{\\theta})$\n",
    "\n",
    "Instead the momentum optimization corrects the weights taking into account also the correction of the previous step. The m parameters controls how much of the previous gradient it has to remember.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/hkt88n7dnks4wq0/momentum.png?dl=0\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages**\n",
    "\n",
    "- Reduces the oscillations\n",
    "\n",
    "- Good to escape from local minima\n",
    "\n",
    "**Disadvantages**\n",
    "\n",
    "- You need to tune an additional hyperparameter: the momentum m\n",
    "\n",
    "- Due to the momentum, the optimizer may overshoot a bit, then come back, overshoot again, and oscillate like this many times before stabilizing at the minimum. This is one of the reasons why it is good to have a bit of friction in the system: it gets rid of these oscillations and thus speeds up convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov Accelerated Gradient\n",
    "\n",
    "Momentum may be a good method but if the momentum is too high the algorithm may miss the local minima and may continue to rise up. So, to resolve this issue the NAG algorithm was developed. It is a look ahead method. \n",
    "\n",
    "The idea of Nesterov Momentum optimization, or Nesterov Accelerated Gradient (NAG), is to measure the gradient of the cost function not at the local position but slightly ahead in the direction of the momentum. \n",
    "\n",
    "NAG will almost always speed up training compared to regular Momentum optimization.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/il4k1j5myn2oska/nesterov.png?dl=0\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaGrad\n",
    "\n",
    "Consider the elongated bowl problem again: Gradient Descent starts by quickly going down the steepest slope, then slowly goes down the bottom of the valley. It would be nice if the algorithm could detect this early on and correct its direction to point a bit more toward the global optimum.\n",
    "\n",
    "$\\Large \\theta \\leftarrow \\theta - \\frac{\\eta}{\\sqrt{G + \\epsilon}} \\nabla_\\theta J(\\mathbf{\\theta})$\n",
    "\n",
    "where \n",
    "\n",
    "G = is a diagonal matrix containing the squares of all previous gradients\n",
    "\n",
    "and\n",
    "\n",
    "$\\epsilon$ = is a very small order of 10$^{-8}$ regularization term that provides numerical stability by preventing division by 0.\n",
    "\n",
    "In short, this algorithm decays the learning rate, but it does so faster for steep dimensions than for dimensions with gentler slopes. This is called an adaptive learning rate.\n",
    "\n",
    "**Advantages**\n",
    "\n",
    "- It quickly converges near the minimum\n",
    "\n",
    "**Disadvantages**\n",
    "\n",
    "- AgaGrad has a monotonically decreasing learning rate. The consequence is that it will never reach the actual minimum. It will stop earlier. For this reason it is never recommended to use AdaGrad for complicated problems.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/rkg477d3cjeomzb/adagrad.png?dl=0\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSProp\n",
    "\n",
    "Although AdaGrad slows down a bit too fast and ends up never converging to the global optimum, the RMSProp algorithm fixes this by accumulating only the gradients from the most recent iterations (as opposed to all the gradients since the beginning of training).\n",
    "\n",
    "How much of the previous gradient is it going to remember at each step? To control this we need to introduce another hyperparameter: $\\rho$. \n",
    "\n",
    "$\\rho$ =0 will remember all the previous steps\n",
    "\n",
    "$\\rho$ =1 won't remember any of the previous steps\n",
    "\n",
    "Default value in Keras: $\\rho$=0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam\n",
    "\n",
    "Adam stands for adaptive moment estimation, combines the ideas of Momentum optimization and RMSProp: just like Momentum optimization it keeps track of an exponentially decaying average of past gradients, and just like RMSProp it keeps track of an exponentially decaying average of past squared gradients.\n",
    "\n",
    "It is probably the best optimizer for complicated problems.\n",
    "\n",
    "The problem is that Adam has two more hyperparameters:\n",
    "\n",
    "- $\\beta_{1}$ = controls the momentum decay (default: 0.9)\n",
    "\n",
    "- $\\beta_{2}$ = controls the scaling decay (default: 0.99)\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/ws6rl15l5kbggqm/adam.gif?dl=0\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to choose the right optimizer?\n",
    "\n",
    "Choosing the right optimizer for your machine learning problem can be hard. More specifically, there is no one-fits-all solution and the optimizer has to be carefully chosen based on the particular problem at hand.\n",
    "\n",
    "As a rule of thumb: If you have the resources to find a good learning rate schedule, SGD with momentum is a solid choice. If you are in need of quick results without extensive hypertuning, tend towards adaptive gradient methods.\n",
    "\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/2mph4hi0nld3x8l/hist_optimizers.jpg?dl=0\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architectures\n",
    "\n",
    "ANNs can have very different architectures.\n",
    "\n",
    "You can inject inputs and extract outputs at any level of the network. In this way you can also do regression and classification at the same time, for example.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/wcsrnajn1eiacrk/ANN_architectures.png?dl=0\" width=\"600\">\n",
    "\n",
    "If you have time series you probably want to use **recurrent NNs*.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/1oc8nm4higyjkt7/recurrent_NN.png?dl=0\" width=\"600\">\n",
    "\n",
    "When you are more interested in detecting outliers or anomalies you can use **autoencoders**.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/04ig8rph4z3v5rh/autoencoder.jpg?dl=0\" width=\"600\">\n",
    "\n",
    "...there is a vast zoo of neural networks.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/s/fe9707zgkg3lhbn/NN_Zoo.png?dl=0\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
